{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML - Do it yourself\n",
    "In this notebook we will get a feel for data generation and a few models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cheatdiy import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using hints and cheatsÂ¶\n",
    "Run the two cells below to learn how to get hints and solutions to the exercises below. You just need to provide the number of the exercise. Exercise 0 is just a dummy to try out the cheating functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cheat(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hint(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Gaussian distribution\n",
    "- Use np.random.randn to sample 1000 numbers from the N(0,1) distribution -- the normal (or gaussian) distribution with mean 0 and standard deviation 1.\n",
    "\n",
    "Whenever you don't know how a function works, run help(function) in any cell, for example help(np.random.randn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = # your code here\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Convert to pandas dataframe\n",
    "- The class you should convert to is pd.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = # your code here\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Histogram\n",
    "- Use np.histogram to compute histogram for x using bins [-3,-2] , [-2,-1], ... , [2,3], i.e. 6 bins.\n",
    " - You should only specify the end points of the bins which can be achieved by using range(start, end).\n",
    "- Use df.hist for the same reason (bonus = plot).\n",
    "- Use plt.hist to plot histogram of x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Multivariate gaussian\n",
    "- Use np.random.randn to sample 1000 two-dimensional vectors independently from the N(0,1) distribution.\n",
    "\n",
    "When we sample in using this function, we the samples we get have mean value (0,0), and the two components of the vector are independent. Also each sample is independent from the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twoD = # your code here\n",
    "twoD.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Scatterplot\n",
    "- Split twoD into two arrays representing the two dimensions.\n",
    "- Use plt.scatter to draw the scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = # your code here\n",
    "y = # your code here\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6: Scale and translate\n",
    "- Transform twoD by scaling both axes by 2.\n",
    "- Transform twoD by adding 5 to x and subtracting 5 from y.\n",
    "- Compute mean (along axis 0) and standard deviation as a sanity check. Means should be close to [5,-5] and standard deviations should be close to [2,2].\n",
    "- Draw the scatter plot again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twoD # your code here\n",
    "twoD[# fill in ] += 5\n",
    "twoD[# fill in ] -= 5\n",
    "print(twoD.mean(axis=0))\n",
    "print(twoD.std(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7: Append more rows\n",
    "- Sample another 1000 samples of 2D gaussian distribution, again N(0,1) independent entries.\n",
    "- Create a concatenated 2D array with twoD followed by the additional samples. For this use np.vstack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_rows = # your code here\n",
    "X = # your code here\n",
    "print(X.shape)\n",
    "assert X.shape == (2000,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8: Adding labels\n",
    "- Make a numpy array with shape (2000,1): 1000 entries of 1 followed by 1000 entries of -1.\n",
    "  - For this use np.vstack and pass it np.ones((1000,1)) and -np.ones((1000,1)). (By the way np.zeros is a similar function).\n",
    "- Stack this to the right of X to obtain a (2000,3) shaped array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = # your code here\n",
    "data = # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert Y.shape == (2000,1)\n",
    "assert Y.sum() == 0\n",
    "assert Y[0] == 1\n",
    "assert data.shape == (2000,3)\n",
    "assert data[:,2].sum() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9: Scatter plot\n",
    "- The first 1000 rows with gray. Color is set by the named argument c.\n",
    "- The remaining rows with pink."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10: Shuffle the rows\n",
    "- Use np.random.permutation to create a random index to shuffle the rows with.\n",
    "- Use indexing to create a shuffled version of the data.\n",
    "- Do the same using np.random.shuffle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm = # your code here\n",
    "data = data[perm]\n",
    "print(data)\n",
    "\n",
    "# your code here to shuffle using np.random.shuffle\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert data[:,2].sum() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Before proceeding to the section about Sklearn, let's split the data into features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all rows and all columns up to but excluding the last one\n",
    "features = data[:, :-1]\n",
    "# select all rows and the last column\n",
    "labels = data[:, -1]\n",
    "print(features.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn\n",
    "Sklearn, or scikit-learn, is a very popular, lightweight and easy to use library for machine learning.\n",
    "It allows you to train models using a few lines of code but still is flexible for extension, varying algorithms, metrics, loss-functions and other hyper parameters.\n",
    "\n",
    "We will train a logistic regression model for the same data set as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML algorithms, or Inducers, in sklearn have few but important methods. Take a look at the help for 'fit' and 'predict'. Also if you type reg.<tab\\> you will see what methods are supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11: Train a model\n",
    "- Fit the logistic regression model to data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see all the values of hyperparameters used above. We can also programatically access them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reg.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights can be accessed like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = reg.coef_[0]\n",
    "c = reg.intercept_[0]\n",
    "(a,b,c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot\n",
    "We use the same code as above to plot the logistic regression decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(extra_rows[:,0], extra_rows[:,1], c='pink')\n",
    "plt.scatter(twoD[:,0], twoD[:,1], c='gray')\n",
    "ticks = [-4 + 0.16*t for t in range(100)]\n",
    "boundary_y = [-(a*x + c)/b for x in ticks]\n",
    "boundary_y = [b if b < 15 else 15 for b in boundary_y]\n",
    "boundary_y = [b if b > -15 else -15 for b in boundary_y]\n",
    "plt.plot(ticks, boundary_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12: Predict and Evaluate the model\n",
    "- Get the model's predictions for the entire data set.\n",
    "- Compute the accuracy of the classifier on the training set.\n",
    "  - You can use compare two numpy arrays to get elementwise comparison.\n",
    "  - You can think of the accuracy as the average accuracy over all rows where accuracy for one row is 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = # your code here\n",
    "assert acc >= 0\n",
    "assert acc <= 1\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 13: Cross validation\n",
    "- Perform 5-fold cross validation with logistic regression by using cross_val_score.\n",
    "- The evaluation metric is accuracy.\n",
    "- Only 1 line of code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LogisticRegression()\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For other metrics see\n",
    "http://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 14: Learning Curve\n",
    "- Retrain the logistic regression model above but use sklearn's validation_curve method to get training and validation scores over training iterations. Specify train_sizes=np.linspace(0.1, 1.0, 200) and use 5 fold cross validation.\n",
    "- Average the output scores over folds.\n",
    "- Plot train scores and test scores in the same plot.\n",
    "- Repeat the above for \"neg_log_loss\" instead of accuracy.\n",
    "  - Note that you'll have to add a minus sign if you want to get positive loss values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes, train_scores, test_scores = # your code here\n",
    "print(train_scores.shape)\n",
    "print(test_scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores_mean = # your code here\n",
    "test_scores_mean = # your code here\n",
    "\n",
    "plt.xlabel(\"number of samples\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.plot(sizes, train_scores_mean, c='red', label='train')\n",
    "plt.plot(sizes, test_scores_mean, c='blue', label='test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat for negative log loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15: Validation Curve\n",
    "- Use np.logspace to create a list of values _params_ $=10^{-4},10^{-3},10^{-2},10^{-1},10^{0},10^{1}$.\n",
    "- Use validation_curve to train a logistic regression model on 'digits' data. The parameter C should take on the values above. Use 5-fold crossvalidation and negative log loss. However when plotting use plt.semilogx instead of plt.plot.\n",
    "- Take averages over folds and plot average train loss and average validation loss vs _params_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import validation_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loads hand written character image data\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "params = np.logspace(-4,1,6)\n",
    "train_scores, valid_scores = # your code here\n",
    "train_scores_mean = # your code here\n",
    "valid_scores_mean = # your code here\n",
    "\n",
    "assert train_scores_mean.shape == (6,)\n",
    "assert valid_scores_mean.shape == (6,)\n",
    "\n",
    "\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('neg_log_loss')\n",
    "plt.semilogx(params, train_scores_mean, label='train')\n",
    "plt.semilogx(params, valid_scores_mean, label='valid')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually setting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.set_params(penalty='elasticnet')\n",
    "reg.set_params(solver='saga')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain\n",
    "Now change 'C' to 'l1_ratio' and rerun your cell above and check the resulting graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 16: Grid search\n",
    "- Read the help on GridSearchCV.\n",
    "- Set parameters correctly so that\n",
    "    - Hint: parameters should be a list of maps, and map values are lists.\n",
    "    - when _kernel_ is 'poly' then _degree_ takes the values 1,2 and 3\n",
    "    - when _kernel_ is 'rbf', then _C_ takes values 1 and 10\n",
    "    - when _kernel_ is 'linear', then _C_ and _gamma_ take on all combinations of \\[1,10\\] and \\[0.1,1\\].\n",
    "- Run the cell to fit a lot of models to iris data or digits data!\n",
    "- Study the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, datasets\n",
    "import pandas as pd\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "parameters = # your code here\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc, parameters, cv=10)\n",
    "clf.fit(iris.data, iris.target)\n",
    "#clf.fit(digits.data, digits.target)\n",
    "df = pd.DataFrame(clf.cv_results_)\n",
    "# should be 9 parameter settings\n",
    "assert df.shape[0] == 9 \n",
    "df.sort_values('mean_test_score', ascending=False, inplace=True)\n",
    "important_cols = [col for col in df.columns.values if not 'split' in col]\n",
    "df[important_cols]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
